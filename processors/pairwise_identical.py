# compares pairs of files for pairwire identicality
# assignment args:
# - allowPartners (bool) - Whether or not partners are allowed for this assignment.
# - files (string array) - Files from the assignment to compare
# detector args:
# - sourceSuffix (string) - Suffix of file generated by preprocessor
# - resultsSuffix (string) - Suffix of file that will be written to postprocessor

import helpers.common as common
from hashlib import sha256
from multiprocessing import Process

def hashText(text):
	return sha256(text).hexdigest()

def runAssignment(assignment, students, args, helpers):
	clusters = {}
	allowPartners = assignment.args["allowPartners"]

	# for each file
	files = assignment.args["files"]
	for filename in files:
		# find collisions
		for student in students:
			safeFilename = common.makeFilenameSafe(filename) + args["sourceSuffix"]
			studentText = helpers.readFromPreprocessed(student, assignment.name, safeFilename)

			if studentText != None:
				hashedText = hashText(studentText)

				if hashedText not in clusters:
					clusters[hashedText] = common.Cluster(allowPartners, filename, 100)

				member = common.Member(student, assignment.name, helpers)
				clusters[hashedText].add(member)

	# process the clusters
	clusterArray = []
	for key in clusters:
		clusterArray.append(clusters[key])

	# write the results for this assignment
	# clustersToStandardJSON will make sure that there are at least two people in the cluster
	common.clustersToStandardJSON(clusterArray, assignment.name, args["resultsSuffix"], helpers)

	# say we're done with this assignment
	helpers.printf("Finished assignment '{}'...\n".format(assignment.name))

# the big kahuna
def run(students, assignments, args, helpers):
	threads = []

	for assignment in assignments:
		# create an empty cluster map for this assignment
		t = Process(target=runAssignment, args=(assignment, students, args, helpers))
		threads.append(t)
		t.start()

	# wait for all to finish
	for t in threads:
		t.join()

	# we did it!
	return True
